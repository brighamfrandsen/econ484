{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brighamfrandsen/econ484/blob/master/examples/ROC%20example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": false,
        "id": "I65dM2nTH3tm"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Import necessary libraries\n",
        "!git clone https://github.com/brighamfrandsen/econ484.git\n",
        "%cd econ484/utilities\n",
        "from preamble import *\n",
        "%cd ../data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HC9aCrgH3tp"
      },
      "source": [
        "#### Import some useful packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": false,
        "id": "-tK5SGvuH3tp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8-whitegrid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38CV5rtdH3tr"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3N1PaWbvN6wm"
      },
      "outputs": [],
      "source": [
        "mortgagedata=pd.read_csv('./mortgage.csv')\n",
        "print(mortgagedata.head())\n",
        "print(\"Shape: {}\".format(str(mortgagedata.shape)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljmcLW9XOFpI"
      },
      "source": [
        "#### Define sets of variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqclBhIdOgP_"
      },
      "outputs": [],
      "source": [
        "y = mortgagedata.loc[:,'deny']\n",
        "X = mortgagedata.drop(['deny','black'],axis=1)\n",
        "print('our y vector is:\\n',y.head)\n",
        "print('our X matrix is:\\n',X.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFeclFZyQG6_"
      },
      "source": [
        "#### Divide into test and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9XSTtk2QKaV"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "n_test=len(y_test)\n",
        "n_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEj2sl4iQPZx"
      },
      "source": [
        "#### Fit logit on training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl-RX8t5H3tr"
      },
      "outputs": [],
      "source": [
        "logit = LogisticRegression(penalty=None).fit(X_train, y_train)\n",
        "print(\"logit.coef_:\", logit.coef_)\n",
        "print(\"logit.intercept_:\", logit.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJVb73EqQhU4"
      },
      "source": [
        "#### Apply predicted probabilities to test set observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7sSukZhH3tt"
      },
      "outputs": [],
      "source": [
        "phat_test=logit.predict_proba(X_test)\n",
        "# the above gives two columns, one for Pr(y=0|x) and the second for Pr(y=1|x). We just need the second\n",
        "phat_test=phat_test[:,1]\n",
        "phat_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me4-lazHUUcK"
      },
      "source": [
        "#### Now make classifications for a range of thresholds, $\\tau$\n",
        "For each value of $\\tau$, calculate the false positive rate and true positive rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51NOGk2pU-T3"
      },
      "outputs": [],
      "source": [
        "tpr=[0]*100\n",
        "fpr=[0]*100\n",
        "\n",
        "for i in range(100):\n",
        "     tau=i/100\n",
        "     yhat_test=phat_test>=tau\n",
        "     tp=sum(yhat_test*y_test)\n",
        "     p=sum(y_test)\n",
        "     tpr[i]=tp/p\n",
        "     n=sum(1-y_test)\n",
        "     fp=sum(yhat_test*(1-y_test))\n",
        "     fpr[i]=fp/n\n",
        "     # on your own: calculate false negative rate:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVUBqSe0l7CT"
      },
      "source": [
        "#### Now plot true positive rate vs false positive rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Fn91f5gH3tv"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = plt.axes()\n",
        "ax.plot(fpr,tpr);\n",
        "plt.title(\"Roar of Cougar\")\n",
        "plt.xlabel(\"False positive rate\")\n",
        "plt.ylabel(\"True positive rate\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOLkpqxCnlM1"
      },
      "source": [
        "#### Calculate Area Under Curve (AUC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORI6RDwlnrmd"
      },
      "outputs": [],
      "source": [
        "dfpr=np.array(fpr[0:99])-np.array(fpr[1:100])\n",
        "AUC=sum(np.array(tpr[0:99])*dfpr)\n",
        "print(AUC)\n",
        "from sklearn import metrics\n",
        "metrics.auc(fpr,tpr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo1rAA2RJWUP"
      },
      "source": [
        "To do on your own: repeat, but standardizing the x-variables and using Lasso to penalize the logit coefficients. Any improvement to AUC?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RjIKRo-bGJe"
      },
      "outputs": [],
      "source": [
        "# standardize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj0k57ALj-Yh"
      },
      "outputs": [],
      "source": [
        "# estimate logit model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXs7PMF_kUAU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "latex_metadata": {
      "author": "Andreas C. M\\\"ller",
      "title": "Machine Learning with Python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}